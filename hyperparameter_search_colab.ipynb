{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Arabic Writer Identification - Hyperparameter Search\n",
    "## Google Colab Version (Optimized for A100 GPU)\n",
    "\n",
    "This notebook runs Bayesian hyperparameter optimization for Arabic writer identification using Optuna.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Single GPU optimization (perfect for Colab A100)\n",
    "- ‚úÖ Google Drive integration (automatic save)\n",
    "- ‚úÖ Quick test mode (10-20 min to verify setup)\n",
    "- ‚úÖ Resumable (can stop and continue)\n",
    "- ‚úÖ NaN detection and safeguards\n",
    "\n",
    "**Runtime:** Make sure GPU is enabled! \n",
    "`Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## Step 1: Mount Google Drive\n",
    "\n",
    "All your data and results will be saved to Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify GPU\n",
    "import torch\n",
    "print(f\"\\nGPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Enable GPU in Runtime settings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upload"
   },
   "source": "## Step 2: Download Script from GitHub\n\nDownload the latest version directly from GitHub (always up-to-date!)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copy_script"
   },
   "outputs": [],
   "source": "# Download latest version from GitHub\nprint(\"üì• Downloading latest script from GitHub...\")\n\n# GitHub repository details\nGITHUB_USER = \"a-mahdi\"\nREPO_NAME = \"WrIHAM-Code\"\nBRANCH = \"claude/analyze-hyperparameter-search-QJqnk\"  # Update this if you merge to main\nSCRIPT_NAME = \"run_hyperparameter_search_colab.py\"\n\n# Construct raw GitHub URL\ngithub_url = f\"https://raw.githubusercontent.com/{GITHUB_USER}/{REPO_NAME}/{BRANCH}/{SCRIPT_NAME}\"\n\n# Download the file\n!wget -q -O run_hyperparameter_search_colab.py \"{github_url}\"\n\n# Verify file exists and show info\nimport os\nif os.path.exists('run_hyperparameter_search_colab.py'):\n    print(\"‚úÖ Script downloaded successfully!\")\n    !ls -lh run_hyperparameter_search_colab.py\n    print(f\"\\nüîó Source: {github_url}\")\nelse:\n    print(\"‚ùå Download failed! Check your internet connection.\")\n    print(f\"   URL: {github_url}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install"
   },
   "source": [
    "## Step 3: Install Dependencies\n",
    "\n",
    "Install required packages (PyTorch should already be installed in Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pip_install"
   },
   "outputs": [],
   "source": [
    "!pip install -q optuna opencv-python-headless seaborn scikit-learn timm\n",
    "\n",
    "# Verify installations\n",
    "import optuna\n",
    "import cv2\n",
    "import seaborn\n",
    "import timm\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")\n",
    "print(f\"Optuna version: {optuna.__version__}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "configure"
   },
   "source": [
    "## Step 4: Configure Paths\n",
    "\n",
    "Set paths to your data and where you want to save results.\n",
    "\n",
    "**IMPORTANT:** Update these paths to match your Google Drive structure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paths"
   },
   "outputs": [],
   "source": [
    "# ========== UPDATE THESE PATHS ==========\n",
    "\n",
    "# Path to your Mirath_extracted_lines folder on Google Drive\n",
    "DATA_ROOT = \"/content/drive/MyDrive/Mirath_extracted_lines\"\n",
    "\n",
    "# Where to save checkpoints and results (will be created if doesn't exist)\n",
    "CHECKPOINT_DIR = \"/content/drive/MyDrive/hyperparameter_search_results\"\n",
    "\n",
    "# ========================================\n",
    "\n",
    "# Verify data path exists\n",
    "if os.path.exists(DATA_ROOT):\n",
    "    print(f\"‚úÖ Data found at: {DATA_ROOT}\")\n",
    "    !ls -d {DATA_ROOT}/train/* | head -5\n",
    "else:\n",
    "    print(f\"‚ùå Data NOT found at: {DATA_ROOT}\")\n",
    "    print(\"   Please update DATA_ROOT above!\")\n",
    "\n",
    "print(f\"\\nüìÅ Results will be saved to: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quick_test"
   },
   "source": [
    "## Step 5: Run Quick Test (RECOMMENDED FIRST!)\n",
    "\n",
    "**Run this first to verify everything works!**\n",
    "\n",
    "Quick test uses minimal resources:\n",
    "- 3 writers (instead of 21)\n",
    "- 50 lines/writer (instead of 300)\n",
    "- Batch size 32 (instead of 128)\n",
    "- 5 epochs (instead of 70)\n",
    "- 2 trials (instead of 12)\n",
    "\n",
    "**Time: ~10-20 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_quick_test"
   },
   "outputs": [],
   "source": [
    "!python run_hyperparameter_search_colab.py \\\n",
    "  --data_root \"{DATA_ROOT}\" \\\n",
    "  --checkpoint_dir \"{CHECKPOINT_DIR}/quick_test\" \\\n",
    "  --quick_test\n",
    "\n",
    "print(\"\\n‚úÖ Quick test completed!\")\n",
    "print(f\"Results saved to: {CHECKPOINT_DIR}/quick_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "full_search"
   },
   "source": [
    "## Step 6: Run Full Hyperparameter Search\n",
    "\n",
    "**Only run this after quick test succeeds!**\n",
    "\n",
    "This will run the full hyperparameter search:\n",
    "- All 21 writers\n",
    "- 300 lines/writer\n",
    "- Batch size 128\n",
    "- 70 epochs per trial\n",
    "- 12 trials total\n",
    "\n",
    "**Time: ~24-48 hours**\n",
    "\n",
    "**Note:** This is resumable! If Colab disconnects, just run this cell again and it will continue from where it stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_full"
   },
   "outputs": [],
   "source": [
    "!python run_hyperparameter_search_colab.py \\\n",
    "  --data_root \"{DATA_ROOT}\" \\\n",
    "  --checkpoint_dir \"{CHECKPOINT_DIR}/full_search\" \\\n",
    "  --n_trials 12 \\\n",
    "  --use_all_writers\n",
    "\n",
    "print(\"\\n‚úÖ Full search completed!\")\n",
    "print(f\"Results saved to: {CHECKPOINT_DIR}/full_search\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "subset"
   },
   "source": [
    "## Alternative: Run with Writer Subset\n",
    "\n",
    "If you want to experiment with fewer writers (faster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_subset"
   },
   "outputs": [],
   "source": [
    "# Run with 7 writers instead of all 21\n",
    "!python run_hyperparameter_search_colab.py \\\n",
    "  --data_root \"{DATA_ROOT}\" \\\n",
    "  --checkpoint_dir \"{CHECKPOINT_DIR}/subset_7writers\" \\\n",
    "  --n_trials 12 \\\n",
    "  --num_writers_subset 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results"
   },
   "source": [
    "## Step 7: View Results\n",
    "\n",
    "After training completes, view the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "show_results"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Choose which run to analyze\n",
    "RESULTS_DIR = f\"{CHECKPOINT_DIR}/full_search\"  # or \"quick_test\"\n",
    "\n",
    "# List all trials\n",
    "print(\"Trials completed:\")\n",
    "!ls -d {RESULTS_DIR}/trial_* 2>/dev/null | head -20\n",
    "\n",
    "# Load best trial summary\n",
    "summary_file = Path(RESULTS_DIR) / \"best_overall\" / \"summary.txt\"\n",
    "if summary_file.exists():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"BEST TRIAL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    with open(summary_file) as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No results yet. Training still in progress or not started.\")\n",
    "\n",
    "# Show training plots\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "plots_dir = Path(RESULTS_DIR) / \"best_overall\" / \"plots\"\n",
    "if plots_dir.exists():\n",
    "    print(\"\\nüìä Training Plots:\")\n",
    "    for plot in sorted(plots_dir.glob(\"*.png\")):\n",
    "        print(f\"\\n{plot.name}\")\n",
    "        display(IPImage(filename=str(plot)))\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No plots found yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## Step 8: Download Best Model\n",
    "\n",
    "Download the best model and results to your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zip_results"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Create a zip of the best model\n",
    "RESULTS_DIR = f\"{CHECKPOINT_DIR}/full_search\"\n",
    "!cd {RESULTS_DIR} && zip -r best_model.zip best_overall/\n",
    "\n",
    "# Download\n",
    "files.download(f\"{RESULTS_DIR}/best_model.zip\")\n",
    "\n",
    "print(\"‚úÖ Best model downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tips"
   },
   "source": [
    "## üí° Tips for Using Colab\n",
    "\n",
    "1. **Colab Timeout:** Free Colab sessions disconnect after ~12 hours. Use Colab Pro for longer sessions.\n",
    "\n",
    "2. **Resumability:** If disconnected, just run the search cell again. It will resume from the Optuna database.\n",
    "\n",
    "3. **Monitor Progress:** Check your Google Drive folder to see trial results being saved in real-time.\n",
    "\n",
    "4. **GPU Memory:** The A100 has 40GB memory, which is more than enough for batch size 128.\n",
    "\n",
    "5. **Save Often:** Results auto-save to Google Drive, so you won't lose progress.\n",
    "\n",
    "6. **Check Status:** Look at the Optuna database file (`optuna_study.db`) to see completed trials.\n",
    "\n",
    "## üö® Troubleshooting\n",
    "\n",
    "**Problem:** \"No GPU available\"  \n",
    "**Solution:** Go to `Runtime ‚Üí Change runtime type ‚Üí GPU`\n",
    "\n",
    "**Problem:** \"Data not found\"  \n",
    "**Solution:** Update `DATA_ROOT` path in Step 4\n",
    "\n",
    "**Problem:** \"Out of memory\"  \n",
    "**Solution:** Add `--quick_test` flag to use smaller batch size\n",
    "\n",
    "**Problem:** Colab disconnected  \n",
    "**Solution:** Just run the cell again - it will resume automatically"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Arabic Writer Identification - Hyperparameter Search",
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}